\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}

% For submission make this a noop

% to be able to draw some self-contained figs
\usepackage{tikz}
%\usepackage{parskip}
\usepackage{mathptmx}\renewcommand{\ttdefault}{cmtt}
\usepackage{amsmath}
\usepackage{wasysym}
%\setlength{\parskip}{1pt} % 1ex plus 0.5ex minus 0.2ex}
%\setlength\parskip{1pt}
\usepackage{graphicx} % http://ctan.org/pkg/graphicx
\usepackage{booktabs} % http://ctan.org/pkg/booktabs
\usepackage{xparse}   % http://ctan.org/pkg/xparse%don't print date
\NewDocumentCommand{\rot}{O{45} O{1em} m}{\makebox[#2][l]{\rotatebox{#1}{#3}}}%
\include{figures}
\usepackage{subcaption}
\usepackage{cleveref}
\usepackage{microtype}
\SetExtraKerning{encoding=*,font=*}{\textemdash={120,120}} % Add space around emdashes
\usepackage[font=small]{caption}
\microtypecontext{spacing=nonfrench}
\usepackage{subcaption}
\usepackage{paralist}
\usepackage{xspace}
\usepackage{soul}
\newcommand{\note}[2]{\hl{[\textbf{#1:} #2]}\xspace}
\newcommand{\nikita}[1]{\note{nikita}{#1}}
\newcommand{\TODO}[1]{\hl{TODO: #1}\xspace}
\newcommand{\TK}{\hl{TK}\xspace}

% Slight JAH fix to stop URLs from breaking after ``http:''
\def\UrlBreaks{\do-\do\.\do\@\do\\\do\!\do\_\do\|\do\;\do\>\do\]%
 \do\)\do\,\do\?\do\'\do+\do\=\do\#}
\def\UrlBigBreaks{\do\:\do\/}%
\urlstyle{rm}

\renewcommand{\paragraph}[1]{\smallskip\noindent\textbf{#1\quad}}

\begin{document}

\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
%\title{\Large \bf Dark Decoys:
%  Conjuring Proxies from Unused Address Space}
\title{\Large \bf Conjure: Summoning Proxies from Unused Address Space}

%for single author (just remove % characters)
%\author{
%{\rm Your N.\ Here}\\
%Your Institution
%\and
%{\rm Second Name}\\
%Second Institution
%% copy the following lines to add more authors
%% \and
%% {\rm Name}\\
%%Name Institution
%} % end author

\maketitle

%\newcommand{\scheme}{Dark Decoys\xspace}
\newcommand{\scheme}{Conjure\xspace}

%-------------------------------------------------------------------------------
\begin{abstract}
%-------------------------------------------------------------------------------
Refraction Networking (formerly known as ``Decoy Routing'') has
emerged as a promising next-generation approach for circumventing
Internet censorship. Rather than trying to hide individual
circumvention proxy servers from censors, proxy functionality is
implemented in the core of the network, at cooperating ISPs in
friendly countries.  Any connection that traverses these ISPs could be
a conduit for the free flow of information, so censors cannot easily
block access without also blocking many legitimate sites.  While one
Refraction scheme, TapDance, has recently been deployed at ISP-scale,
it suffers from several problems: a limited number of ``decoy'' sites
in realistic deployments, high technical complexity, and undesirable
tradeoffs between performance and observability by the censor. These
challenges may impede broader deployment and ultimately allow censors to
block such techniques.

We present \scheme, an improved Refraction Networking approach
that overcomes these limitations by leveraging unused address space at
deploying ISPs. Instead of using real websites as the decoy destinations
for proxy connections, our scheme creates seemingly legitimate hosts
on demand, at IP addresses where no web server exists.
These phantom hosts are difficult for a censor to distinguish from
real ones, but can be used by clients as proxies.  We define the
\scheme protocol, analyze its security, and evaluate a
prototype using an ISP testbed.
Our results suggest that \scheme can be harder to block
than TapDance, is simpler to maintain and deploy,
and offers substantially better network performance.

\end{abstract}


\FigHighLevel

%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------
% 1.5-2 pages



%Censorship circumvention still important
%-More countries blocking
%-Existing countries blocking more
%Internet censorship continues to hamper social progress throughout the world.

Over half of Internet users globally
now live in countries that block political, social, or religious content
online~\cite{fotn2018}.
%Existing circumvention strategies on shaky ground
%-domain fronting going away
%-active probing of existing proxies
%-Cenosrs fingerprinting known protocols
Meanwhile, many popular tools and techniques for circumventing such censorship
have ceased to function, because censors have evolved new ways to block them~\cite{ensafi-tor,great-cannon}
or infrastructure they rely on has become unavailable.

For example, domain fronting~\cite{meek} was a popular circumvention
strategy used by Meek (in Tor), as well as by the Signal secure messaging app to
get around censorship in countries where it was
blocked~\cite{signal,signal-domain-fronting}.
But in May~2018, Google and Amazon made both technical and policy changes to
their cloud infrastructures that removed support for domain
fronting~\cite{aws-front}. While meek
continues to use other cloud providers that (for now) continue to allow domain
fronting, Signal abandoned the strategy altogether~\cite{signal-back-on-front}.
There is an urgent need for new, more robust approaches to circumvention.

%Combined with censors' constant improvements in discovery and blocking
%techniques~\cite{ensafi-tor,great-cannon}, ...

%Importance of Refraction Networking
%-what it is, how it solves many of the above problems
%-acknowledge challenge of ISP deployment, cite TapDance deployment as only refraction technology that has overcome this challenge so far
A family of techniques called Refraction Networking~\cite{telex11,cirripede11,curveball11,tapdance14,rebound15,slitheen16,waterfall17}, formerly known
as Decoy Routing, has made promising steps towards that goal.
These techniques operate in the network's core, at cooperating Internet Service Providers
(ISPs) outside censoring countries~\cite{refraction-site}.  Clients access circumvention service by connecting to a ``decoy site''---any uncensored website for which the connection travels over a participating ISP\@.  Upon recognizing a steganographic signal from the client, the ISP modifies the connection response to return censored content requested by the user.
Censors cannot easily block access without also blocking legitimate connections to the decoy sites---collateral damage that may be prohibitive for censors if Refraction is widely deployed~\cite{robinson2013collateral}.

However, deploying such schemes is more difficult than with most
edge-based circumvention techniques, since ISPs must be convinced to
operate the systems in their production networks.  To date, only
TapDance~\cite{tapdance14}, one of six Refraction Networking
proposals, has been deployed at ISP scale~\cite{frolov2017isp}.

TapDance was designed for ease of deployment.
Instead of in-line network devices required by earlier schemes, it
calls for only a passive tap.
This ``on-the-side'' approach, though much friendlier from an ISP's
perspective, leads to major challenges when interposing in an ongoing
client-to--decoy connection:
\begin{compactitem}
\item Implementation is complex and error-prone, requiring kernel
  patches or a custom TCP stack.
\item To avoid detection, the system must carefully mimmick
  subtle features of each decoy's TCP and TLS behavior.
\item The architecture cannot resist active probing attacks, where the
  censor sends specially crafted packets to determine whether a
  suspected connection is using TapDance.
\item Interactions with the decoy's network stack limit the length and
  duration of each connection, forcing TapDance to multiplex
  long-lived proxy connections over many shorter decoy
  connections. This adds overhead and creates a traffic pattern
  that is challenging to conceal.
\end{compactitem}

%Challenges remain in Tapdance:
%-Censor can fingerprint decoy sites
%-Decoys themselves are limited (e.g. a few dozen in many cases)
%-Can't have long-lived connections (performance and observability issue)
%-Other performance limits (upload limit, TCP window size)

%% AH: I'm not sure I buy this limited decoys argument. If there are
%% few decoys, there is little collateral damage of blocking
%% everything in the AS, and \scheme is at a big disadvantage too.
%The use of real-world decoy sites also presents practical problems: If
%decoys are limited or not particularly important, it may be easy for a
%censor to block them altogether without much collateral damage.

%Dark decoys solve these issues
%-Create new decoys from ``dark'' (unused) address space
%-Clients register (via TapDance-like or other robust protocol (email, blockchain, whatever))
%-Connect to custom IP address, talk whatever protocol client/station agrees on

\smallskip

In this paper, we present \textbf{\scheme}, a Refraction
Networking protocol that overcomes these challenges while retaining
TapDance's ISP-friendly deployment requirements.
Our key innovation is an architecture that avoids
having to actively participate in client-to-decoy connections.

\TODO{more precise:}
In our scheme (Figure~\ref{fig:highlevel}), clients
request the creation of phantom hosts in the ``dark''
or unused address space of the deploying ISP. Once registered, clients
can connect to these phantom hosts IP addresses as if they were real
proxy servers. The ISP station acts as the other end of these connections, and
responds as if it were a legitimate site or service. To the censor,
these phantom hosts appear as legitimate sites or services, and even
active probes will not reveal information that would allow the censor to
block them.

%% requests service
%% by embedding a steganographic registration message in a TLS handshake
%% with a decoy site. This message, which the ISP station can passively
%% observe using a private key, uniquely determines an IP address within
%% the ISP's address space. If there is no server running at that address,

%One-time use address advantages:
%-Censor cannot actively probe ahead of time (especially in IPv6), making it hard to fingerprint
%-Decoys are now virtually unlimited (or limited only by address space)
%-Connection can live as long as we want
%-No pesky TCP/TapDance-y limits

Phantom hosts are cheap to create, allowing for discardable \textbf{one-time use}
proxy servers to be used by clients. This greatly increases the cost for censors to
block, as they must detect and block in real time. Meanwhile, even a censor that
can detect 90\% of phantom hosts does not significantly increase the cost to the
circumvention system, giving \scheme an advantage in the censor/circumventor
cat-and-mouse game.
\scheme supports both IPv4 and IPv6, though we note that the technique is especially
powerful in IPv6, where censors cannot exhaustively scan the address space
ahead of time to identify addresses that change behavior.
Because we fully control the transport connection, connections can live as
long as needed, without the complexity faced by TapDance.

%TODO:
%Requirements/Challenges
%-Censor can't be able to distinguish between dark decoy and legitimate hosts
%    (otherwise they block all dark decoys)
%    -Includes active probing: censor shouldn't be able to register existing IP
%-Disruption avoidence: Want to pickup even for used addresses
%    -Otherwise, censor probes to find truly unused address space and blocks
%    -But can't disrupt legitimate services
%    -Can overcome by limiting pickup to the registering client (but spoofing challenges...)
%    -Note: also likely solved by the client-sends-SNI in the Mask site application...

% We implement it, it works...

We introduce the \scheme protocol (Section~\ref{sec:architecture})
and analyze its security, finding that it resists a broader
range of detection attacks than TapDance.
We have implemented a prototype implementation (Section~\ref{sec:implementation})
and deployed it on a 10~Gbps testbed similar to the TapDance
deployment~\cite{frolov2017isp}.  Compared to TapDance, we find that
\scheme has reduced complexity and substantially improved performance
(Section~\ref{sec:evaluation}).

\input{background.tex}


\section{Threat Model}
% 0.25 page


Our deployment model is identical to that of TapDance: we only require a passive
tap at the deploying ISP, and the ability to inject (spoofed) traffic from dark
decoy sites.
Furthermore, we assume
asymmetric routing (i.e. that the tap can sometimes only see packets from but not to the
client).
However, we assume a stronger threat model for the adversary than
TapDance, as our design resists active attacks.


We assume the censor can block arbitrary IP addresses and networks, but faces a
cost in doing so if it blocks potentially useful resources. In particular, we
assume it is difficult for the censor to have complete knowledge of legitimate
addresses used, and so instead resorts to a blacklist approach to blocking
proxies and objectionable content.
Whitelists are expensive for censors to maintain and can stifle
innovation, and are rarely employed by censors.


We assume that the censor can know what network the dark decoy station(s) are
deployed in and the prefixes dark decoys are selected from, but that blocking those
networks outright brings a collateral
damage the censor is unwilling to suffer. Instead, the censor aims to identify
the addresses that are dark decoys, and block only those.

We assume the censor can use the client to register and access its own dark
decoys, but that these will not reveal the dark decoys of other users. The
censor can also actively probe addresses that it sees users accessing, but can
not enumerate the entire dark decoy prefix (e.g. a /32 IPv6 prefix contains
$2^{96} addresses$).

Finally, we assume the censor can replay or preplay any connections that it
suspects involve dark decoys (or their registration) in an attempt to confirm.
However, the censor wishes to avoid disrupting any connections before it
knows for certain they are dark decoy ones, lest they disrupt legitimate
connections. This means that injecting false data or corrupting TLS sessions is
outside the scope of the censor, but that the censor can send non-disruptive
probes (such as stale TCP acknowledgements or other packets that would normally
be ignored). We emphasize that TapDance is observable by censors that can send
TCP packets in suspected connections, but that our protocol is robust against
this class of censor.

%-Censor can block arbitrary addresses (or networks), but faces a cost in doing so (collateral damage)
%-Censor can know what network deploys the dark decoy station
%-Censor knows the dark decoy prefixes distributed in the client, but they contain legitimate hosts
%-Censor can use the client
%-Censor can active probe limited sets, but cannot enumerate the entire prefix (i.e. IPv6 /32)
%-Censor can active probe or (p)replay connections it suspects


\section{Architecture}
\label{sec:architecture}
% 3 pages

\scheme involve three main steps. First, clients \textbf{register} with the
ISP station,
and agree on the dark decoy IP address that will be used. Next, the client
connects to the agreed upon address, which is terminated by an
\textbf{application} running on the station. Finally, the client \textbf{proves}
to the application that it was the same client that registered (and not a censor
attempting to probe), and is able to use the application as a proxy.

Similar to previous schemes, our design does not require expensive in-line
flow blocking, and can be accomplished with only a passive tap at the ISP.
Our architecture is also modular, in that the registration and application steps operate
independently, allowing a wide range of flexibility to evade censors. We
describe each of these components.

\subsection{Registration}

Clients can register intent to use the proxy in several covert ways. For
instance, they could use email or other existing intermitently available proxies
to register. In this section, we use a form of Refraction Networking similar to
TapDance to register directly with the station.

Registration is unidirectional (client to server) and does not require any
acknowledgement of receipt. To ensure receipt, clients can attempt to register
multiple times (possibly via multiple methods) with the same information, and expect
that one gets through.

\medskip

To register, clients connect to a \textbf{decoy} site that supports TLS. They
complete the handshake, and send a normal HTTPS request that embeds a special
steganographic \textbf{tag} in the ciphertext of the request. We use
the same technique used in TapDance's covert ciphertext channel\footnote{Section 3 in
TapDance~\cite{tapdance14}} to embed the tag, but we purposefully have the client
send a complete request (rather than incomplete), allowing the decoy server to respond.
The steganographic tag is only visible to the ISP station, which can see the tag using its
private key. Unlike in TapDance, the \scheme station can passively observe
the tag, and does not need to respond to it (which requires mimicking the
decoy)


The tag contains a public key (encoded to be indistinguishable from random using
Elligator~\cite{elligator}), and a message encrypted under the shared secret
derived from a key exchange with the station's long-term public key hard-coded
in the client software. The station uses its private key to compute the same
shared secret from the (decoded) public key, and decrypts the message in the
tag. The censor, without knowledge of either the station or client's private
key, cannot derive the shared secret, preventing it from being able to decrypt
the message, or even learn of its existence.


Inside the message, the client communicates a random \textbf{seed}, and other
configuration-specific information, such as flags to signify version, feature
support, and a set of IPv6 network prefixes that the client knows can be used
for dark decoys (previously distributed publicly).
The client and server hash the seed to determine which specific
IPv6 address from the set of prefixes will be used and registered as a dark
decoy. It may seem intuitive to instead have the client
send the specific IP address to register, but allowing the client arbitrary
choice also allows the censor to register suspected dark decoys and block them if
they pick up. 
By using a hash of a seed, the censor would have to pre-image the hash to
obtain a seed it could use to register for a desired IP address.
It also gives a
secret (the seed) that only the client and station know, even after the client
connects to the dark decoy address.

Once the dark decoy IP address has been selected, the station watches for
packets destined to that address, and forwards them onto the dark decoy
\textbf{application}. The station can also optionally ignore packets not from
the source IP address of the registering client, so that to a probing censor
from a different IP address,
the dark decoy appears to be firewalled off from all but the client. We note
this is not a robust solution: censors have previously been observed taking over
IP addresses of clients~\cite{ensafi-tor}. We instead address active probing in
the application.

\subsubsection{IPv6 vs IPv4 dark decoys}


Dark decoy IP addresses must be derived from network blocks that are routed (so they pass
the ISP station) and contain other legitimate hosts (so that censors cannot
block the entire network without collateral damage).
Because of the large number of IPv6 addresses, even
relatively small network prefixes have astronomical numbers of addresses: a
single /32 prefix has $2^{96}$ possible addresses. Therefore, client-chosen
seeds have negligible probability of corresponding to addresses that are already
being used by legitimate hosts. This allows us to select dark decoy addresses
from network prefixes that contain
legitimate hosts---crucial to discouraging the censor from blocking them
outright---without worry that registrations could interfere with legitimate
services.

In addition, the use of IPv6 prevents censors from exhaustively probing
potential dark decoy network prefixes ahead of time to learn the full set of
legitimate sites in the network.

\paragraph{IPv4}
While \scheme composes well with IPv6, we can also support IPv4,
at the cost of being vulnerable to active probing by the censor.
We emphasize that TapDance is already
vulnerable to active probing attacks~\cite{tapdance14} that \scheme defends
against when using IPv6. However, in IPv4, there are substantially fewer
addresses, allowing censors to easily enumerate network prefixes that pass by
the ISP station and measure legitimate sites. Furthermore, the small address
space makes it much easier to pre-image the hash used to derive IP addresses
from the seed. Registering a specific IPv4 address in an IPv4 /16 subnet will
take only an expected $2^{16}$ hashes for the censor to achieve. This would let
attackers register legitimate hosts as dark decoys, potentially disrupting
legitimate service. If the station refused to pick up for addresses that
correspond to legitimate hosts (measured by scanning during registration), then
censors could use this as an oracle for distinguishing legitimate sites from
dark decoys. Still, IPv4 \scheme offers many performance, flexibility, and
simplicity benefits over TapDance, though they are both vulnerable to active
probing attacks.


%While address utilization in IPv4 is quite high (all blocks have been allocated
%at the RIR level), the fraction of addresses that respond to TCP connections on
%a given port is quite low: even popular ports like 443 (use by TLS) have less
%than 2\% of IPv4 hosts respond to connection requests. This leaves a large
%number of hosts available to use as dark decoys. However, if a client registers
%a dark decoy address that is already happens to be used by an existing host,
%there will be multiple responses when the client tries to connect, and the
%connection will fail. However, this failure is still limited to the registering
%client, as the application only responds to the IP of the client that
%registered. In IPv6, the odds of picking a legitimate host are negligible: with
%a /32 prefix of IPv6, there are $2^{96}$ addresses to choose from.
%\nikita{/32 is pretty big, e.g. UIUC only has a /48}


\subsection{Applications}


Once the client has registered, packets sent to the dark decoy IP address are
passed to the \textbf{application} running on the station. The application has
two main jobs: first, it must look like an innocuous legitimate service to the
censor, and second must allow the client to use it as a proxy.

Any protocol that satisfies these criteria can be used as an application. For
instance, \texttt{obfs4}~\cite{obfs4} is a pluggable transport used by
Tor~\cite{tor} that could be
modified to meet these needs: it requires each endpoint to have knowledge of a
shared secret (which we can derive from the seed shared by the client and
station during registration), and attempts to be a protocol with no discernible
fingerprint. Probing censors that do not have the shared secret receive no
response, while clients that have the secret can communicate with the proxy.

However, even though \texttt{obfs4} is indistinguishable from random, there are
still known attacks that can differentiate it from other
traffic~\cite{wang2015seeing}. While we have yet to see evidence of such attacks
employed in practice by censors, we consider two alternatives built on TLS.


\FigOverview

\subsubsection{Mask Sites}

TLS is a natural protocol for dark decoy applications, because it is ubiquitous on
the Internet (making it difficult for censors to block), while also providing
strong cryptographic protection against passive and active network adversaries.
However, there are several challenges to make it robust against censors that
wish to block a particular service.

This is because TLS sends important server-identifying content in plaintext
during the TLS handshake. This includes the Server Name Indication (SNI) in the
Client Hello message that sends the domain name of the server, and the
X.509 Certificate sent by the server.

To evade censors, we must send a plausible SNI value (sending no SNI is
uncommon and easily blocked---study conducted using Colorado University network
infrastructure shows that only 1\% of all TLS connections coming in and out of 
campus do not carry the
SNI extension~\cite{tls-fingerprint}), and we must have the server respond with
a plausible (and corresponding) certificate. Even if we manage to avoid sending
either in the clear, censors could actively probe the server in a
way that would normally elicit a certificate.


We therefore attempt to mimic an existing \textbf{mask site}, by relaying
traffic between the client and a selected mask website. To a censor, this site
will be indistinguishable from the legitimate mask site, making it difficult for
them to block without potentially blocking the actual site. TLS connections to the
application will terminate exactly as connections to the mask site would, with the
application acting as a transparent proxy between the client and mask site.
However, this leaves the application unable to introspect on the contents of the
TLS connection to the mask site, as it does not have the client-site shared
secrets, and it cannot overtly man-in-the-middle the connection before knowing
it is communicating with the legitimate client (and not the censor).


To accomplish this, the client changes the shared secret it derives with the
mask site to something that the application can also derive. The client's first
\texttt{Application Data} packet is thus encrypted under a different secret than
the client/mask site secret. Specifically, the client uses the \textbf{seed}
sent during registration to derive the pre-master secret for the connection.
This is hashed along with the client and server randoms of the current (mask
site) TLS connection to obtain the master secret that determines
encryption/decryption/authentication keys.

The application can determine if the client did this by trial decryption with
the master secret derived from the known \textbf{seed}. If it succeeds, the
client has proved knowledge of the \textbf{seed}, and the application can
respond as a proxy. If not, the application simply continues to forward data
between the client and the mask site. As the censor does not have knowledge of
the \textbf{seed} used in registration, it cannot coerce the application to
appear as anything besides the mask site.


\paragraph{Mask Site Selection}

Selecting which sites to masquerade as must be done carefully to avoid censors
being able to detect obvious choices. For example, if a small university network
has a dark decoy in their network that appears to be \texttt{apple.com}, it
would be easy for a censor to block as a likely non-legitimate host. Likewise,
if a dark decoy at an IP address pretends to be a domain (\texttt{example.com}) that
globally resolves to a single different IP address, the censor could also
identify and block the dark decoy.

\smallskip
\noindent
\emph{Nearby sites} - One strategy for selecting mask sites to mimic is to pick websites that are
legitimately hosted in or near the network of the dark decoy addresses. This
effectively creates copies of legitimate sites, with the censor unable to
determine which copies are real and which are the dark decoys. However, as
mentioned, other signals such as DNS may reveal the true mask site.

\smallskip
\noindent
\emph{Popular sites} -
An alternative strategy is to use popular sites, such as those from the Alexa
top site~\cite{alexa-top500} list. As mentioned previously, it may be wise to avoid
sites that are obviously not hosted in the dark decoy address range, such as
large companies that run their own datacenters and own their own ASN.
The list could also be filtered to domains that resolve to different IP
addresses from different vantage points, making it harder for a censor to know
if a dark decoy corresponds to a domain's IP.

\smallskip
\noindent
\emph{Passive observation} -
The ISP tap could also collect sites by passively observing DNS requests, TLS
SNI, or certificates that pass by. This would allow for building a realistic set
of sites that are plausibly in the vicinity of the dark decoy addresses
that pass by the tap. It also has the added bonus of being able to discover
IPv6 addresses that could be used as decoys (for registration), where active
scanning would be infeasible.

In practice, clients can often try multiple dark decoys/mask sites over
several attempts, as blocking the client outright may negatively impact other
unrelated users behind the same network (e.g. in the case of NAT). Thus, even a
censor that can block most (but not all) mask site only delays access, and
doesn't prevent it outright.

\subsubsection{Encrypted SNI}
\label{esni}

TLS~1.3~\cite{tls13} offers several features that may greatly simplify dark
decoy application design. For instance, TLS~1.3 handshakes include encrypted
certificates, potentially obviating the need to impersonate mask sites.
Unfortunately, TLS~1.3 currently still sends the SNI in the (plaintext) Client
Hello, meaning we would still have to choose a realistic domain to fool a
censor.

However, there are proposals to encrypt the SNI in the Client Hello~\cite{esni},
though none have been implemented or deployed as of early 2019. Nonetheless,
if widely adopted, Encrypted SNI (ESNI) would offer a powerful solution for dark
decoy applications by allowing the domain to remain hidden from the censor.
While the censor could still try to actively probe with guesses for the SNI,
servers could respond with generic ``Unknown SNI'' errors. If such responses
were common for incorrect SNI, the censor's efforts to identify dark decoys
would be frustrated.

\subsubsection{WebRTC}
\label{sec:webrtc}

Dark Decoys could also pretend to be clients instead of servers. This may
potentially give censors less to block on, as actively probing clients is common
to return few or no open ports. Nonetheless, a censor may be hesitant to block
client-to-client communication, as it could block peer-to-peer applications as
well as many video conferencing protocols. WebRTC is a
natural choice for a client-to-client protocol in censorship circumvention,
and is used in existing censorship circumvention schemes like
Snowflake~\cite{snowflake}. Dark decoy applications could also use WebRTC as the
application protocol, convincing the censor that two clients are communicating.

\section{Implementation}
\label{sec:implementation}

We implemented the Dark Decoy protocol and tested it in a 10~Gbps ISP testbed
with real traffic. Similar to TapDance~\cite{tapdance14}, we used PF\_RING to
consume the 10~Gbps link, and feed it to a custom \textbf{detector} written in Rust. The
detector processes all packets and watches for new registrations. It also
forwards all packets sent to a (registered) dark decoy's address to the local
\textbf{application} via an \texttt{iptables} DNAT rule that rewrites the destination IP,
allowing the application to accept and respond to connections using the native
operating system's interface. Figure~\ref{fig:implementation} shows the overall
architecture of our implementation, which we describe next.
% Along with the client?

\FigImplementation

\subsection{Detector}

Our detector is a modified fork of the open source TapDance
implementation~\cite{tapdance-source}.
We implemented our detector in approximately 1,800 lines of Rust (compared to
over 5,000 lines for TapDance)\footnote{excluding (from both) about 3,000 lines
of auto-generated protobuf code}.

We used PF\_RING to load balance the 10~Gbps link over 4~CPU cores. PF\_RING
supports balancing across cores based on flow (5-tuple) or source and
destination IPs. However, both of these options present challenges for our Dark
Decoy detector. One issue is that registrations could be processed on a
different core than the packets sent to that specific dark decoy address. For
instance, a client could have its registration handled by Core 1, while its
packets to the dark decoy address end up on Core 3, which doesn't know about the
original registration.

To address this, we used Redis~\cite{redis} to allow each process to announce
(publish) newly registered decoys to the other cores so they can
add them to their local list of registered dark decoy addresses.
However, this introduces two new problems. First, a core might add a
registration \emph{after} it has already received and processed packets destined
for the specified dark decoy. This typically isn't a problem when running on a
single core, as packets are processed sequentially. Second, each core may
timeout each dark decoy at different times, potentially leading to differing
behavior that is visible to a censor. For instance, if we used the
source/destination IPs to load balance, a censor's packets to a dark decoy could
be processed by a different core than the client. If the censor waits for the
known timeout before sending a probe, its core may have timed out that dark
decoy, while the client's core has refreshed the timeout of the dark decoy due
to active use.

To address the first issue, we force the client to delay sending its connection
to the dark decoy until a short time after registration. In practice, we force
the client to wait until the registration decoy responds before starting a
connection with the registered dark decoy.

To address the second issue, we implemented a new load-balancing algorithm in
PF\_RING to select the core based solely on the destination IP address of the
packet. This still means we must use Redis to tell all of the cores of new
registrations, but that only one core will be responsible for processing all of
the packets sent to a given dark decoy, regardless of who or when it is sent.


\subsection{Application}

We implemented our application in about 500~lines of Golang. Though we note
other protocols (e.g. obfsproxy or WebRTC) could be used as the application, we
implemented a mask site mimicking application, that pretends to be a mask site
when actively probed by the censor.

The application accepts connections to dark decoy addresses forwarded by the
detector and rewritten to the local address using \texttt{iptables}.
The application also receives out-of-band information about registrations from the
detector via a ZMQ~\cite{zmq} connection, which informs the application of the
registering client's IP address, the secret seed, and other configuration
information passed by the client.

Once the application accepts a connection, it initially acts as a transparent
proxy to the mask site specified by the client during registration. The
application parses the handshake, forwarding packets back and forth between
client and mask site without modification, and extracting the server and client
randoms. The application attempts to decrypt the first application data record
from the client using a key derived from the secret seed, and client and server
randoms. We use the uTLS library~\cite{utls} on both the application and client
to allow us to change the TLS secrets being used after the handshake.

If the decryption is successful, the application switches to forwarding
(decrypted) data back and forth with a client-specified endpoint, such as a
SOCKS proxy, which can multiplex multiple client connections over the single
connection to the dark decoy.

\subsection{Client}

Our client is also written in Golang, and uses a TapDance-like protocol for
registration. We note that this protocol should be harder for censors to observe
because it consists of only a single (complete) request, and the station does
not have to spoof packets as the decoy used during registration, only passively
observe them.

After registering, the client connects to the derived dark decoy address, and
switches secrets after the handshake. At this point, a local application (e.g.
SOCKS client) can connect to the client, and it will transparently be connected to
the remote end via the encrypted dark decoy connection.

\if0
In order to scale up to 10Gbps and beyond,
one has to utilize multiple cores and employ load balancing.
We use PF\_RING built-in load balancer \emph{zbalance} to efficiently
distribute load between 4 cores.
Our timeout is based on last IP address usage time, which prevents us from
balancing load based on source IP address,
as censor would be able to observe
same destination IP address picking or not picking up
depending on source IP address.
To avoid such unusual behavior we balance on destination IP.
Since PF\_RING does not feature load balancing based only on destination
IP address, we made a custom implementation of this zbalance policy.

TODO: say it's tested on 10 Gbps

Implementation of the protocol includes 3 components:
dark decoy detector, proxy application, and client.
Dark decoy detector will parse the traffic, searching for registrations in
tagged messages. After detector observes a registration, and negotiates with client
a dark decoy IP,
all packets, that are sent to that dark decoy IP,
will be forwarded into a proxy application.

\subsection{Registration phase}

Each Dark Decoy connection has 2 phases: registration, and usage of a dark decoy.
Registration starts with a handshake that is similar to a TapDance handshake,
but initial HTTP request is complete.
This allows a reachable site to provide a genuine response
to a HTTP GET request of its index page.
Since station does not need to produce a response,
which significantly reduces complexity of a detector,
that does not need to decrypt and inject packets into a TLS connection between
client and a reachable site, as opposed to original TapDance.

Client begins registation by establishing TLS connection
to one of the reachable websites,
path to which passes by our tap.
Client uses a Chosen-Ciphertext Steganography technique~\cite{tapdance14} to manupulate
plaintext of a first application data HTTP request
to get desired ciphertext,
and exchange keys with the station.
After client writes Elligator-encoded~\cite{elligator} representative into the ciphertext at a static offset of 92 bytes from the end,
that could be decoded using station's private key,
to negotiate a 32 byte Eligator-encoded~\cite{elligator} shared secret between the client and the station.
That shared secret is used as a seed of SHA-256 based key derivation function (HKDF),
allowing station and client to derive an unlimited amount of shared secrets.

Elligator representative on the wire is immidiately followed by a 6 bytes long AES-GCM-encrypted
fixed size payload(FSP), that holds flags and the size of the variable size payload(VSP).
IV and key for encrypted of both FSP and VSP will be derived from HKDF.
Once FSP is decrypted and the size of VSP is known, station can decrypt the VSP as well.
VSP itself is a protobuf, which allows us to easily change the contents of VSP without risk of version mismatch, and currently contains 3 fields: version of configuration(which includes list of decoys), SNI of mask site, and a presumably blocked target host that client would like to get connected to.

Client will sleep a short randomized period of time before attempting to establish connection to dark decoy.
This is done for 2 reasons: to break potentially observable interflow dependency with a dark decoy connection being established right after a first application layer data packet sent to decoy,
and to give station time.
TODO: why does it need time?

\subsection{Application phase}
Client and station will use HKDF to derive 16 random bytes and use them to
agree on a dark decoy IP address, by applying a simple selection algorithm.
Algorithm is as follows: first, flatten a list of pre-shared avaliable IP
addresses in various subnets into a single indexed list, then make a 128-bit
integer out of 16 random bytes and divide it by the length
of the flattened list, and use the remainder of this division as an index
of the list to pick an IP address.

To thwart active probing attacks, this application will then confirm
that connecting client knows a secret, negotiated during the registration.
If connecting client does know that secret, application will set up proxying,
otherwise it may give censor a response, that acts like that this IP address
is not an open proxy.

TODO: describe MakeConnWithCompleteHandshake?

Note that dark decoy detector and proxy application are only loosely coupled with each other,
making it simple to replace one of them.
We plan to take advantage of encrypted SNI, when it gets widely adopted,
and replace our current proxy implementation with one that uses encrypted SNI
and achieve improved unobservability properties, described in section~\ref{esni}.

\subsection{Languages and LOC counts} % TODO: rename/restructure and complete section
Client is written in Golang and follows the same API as standard TapDance does,
which allows us to reuse existing TapDance CLI wrapper and Android application.

-Language choice (Rust, Go, minimal C)
-Open source (client, station and application)
\fi


\section{Evaluation}
\label{sec:evaluation}
% 1 page

%\TODO{Write (1 page)}


\FigTapBandwidth

\FigUpload

\FigDownload

To evaluate our \scheme implementation, we compare its bandwidth
to that of TapDance in a realistic ISP setting. We used a full duplex 10~Gbps
network tap at a mid-sized ISP and run both implementations on a 1U server with
an 8-core Intel Xeon E5-2640 CPU, 64GB of RAM, and a dual-port Intel X710 10GbE SFP+
network interface. A typical week of bandwidth seen on the tap is
shown in Figure~\ref{fig:tap-bandwidth}, ranging from 2.4~Gbps to peaks above
17~Gbps.


We evaluated the performance of a client from a Singapore-based VPS,
Figures~\ref{fig:upload} and~\ref{fig:download} show the upload and download as
measured by iperf for TapDance, our \scheme implementation, and a direct
connection to our iperf server in the ISP's network.

TapDance must reconnect if the amount of data sent by the client
exceeds a short TCP window (typically on the order of 32~KBytes) or the
connection persists until a timeout (18-120 seconds). At each reconnect, the
TapDance client naively blocks until a new TLS connection to the decoy and
station has been established. Thus, when uploading files, TapDance has to create
a new TLS connection for every 32~KBytes of data it sends, limiting its average
upload bandwidth to less than 1~Mbps due to the high overhead. In contrast,
our \scheme implementation is
able to maintain the same connection during large uploads, and achieves
performance inline with the direct connection.

During download-only workloads, TapDance is able to better utilize the network,
but must still reconnect before the decoy times out. In our tests, we see
TapDance reconnect every 25 seconds, which can negatively impact the performance of
downloads or any real-time streaming applications. Again, our \scheme
implementation is able to maintain a single connection and provide the maximum
download rate without interruption.

%Compare to TapDance performance:
%-Connection setup time
%-Connection/session lifetime
%-Throughput (especially upload vs download)
%-Security considerations


\section{Discussion}


\subsection{Attacks and Defenses}
% 1 page

There are many attacks a censor might attempt to either prevent dark decoys from
being registered or used.

\paragraph{Blocking registration}
To make registration more difficult, censors could block TLS connections to all of the
limited decoys available in a deployment. Using TapDance's current deployment,
this would involve blocking over 1500 sites. We note that such an attack would
completely disable all existing Refraction Networking schemes, as none work
without being able to access legitimate decoys past the station. In dark decoys,
this would only block new registrations, and would not impact users that
previously registered. Furthermore, registrations could also occur over email,
or over lower-bandwidth covert channels, such as port (or even IP) knocking past
the station, that would be more difficult for the censor to block.
%Cirripede previously used a registration protocol that sent covert information via initial
%sequence numbers in arbitrary TCP connections, though we note this solution
%generally requires clients to have root access to their device to control the
%initial sequence numbers. Since most mobile users do not have such control, we
%suggest other methods be used instead.

\paragraph{Scanning masked sites}
The censor could also attempt to fingerprint the masked site and compare it to a
suspected dark decoy application. For instance, if a dark decoy IP responds as
pretending to be \texttt{example.com}, the censor could scan or probe real instances
of \texttt{example.com} on different ports and see how it responds. Then, the
censor can probe the dark decoy IP, and see if it responds similarly (e.g. with
the same set of open ports and payloads for certain kinds of probes). To defend
against this, we forward \emph{all} traffic destined to the dark decoy to the
masked site, including ports that are not relevant to the proxy application
(e.g. non 443). This ensures that above the TCP layer, we appear to be the mask
site. However, there may be differences in TCP/IP implementations, for instance,
how IP IDs are incremented, or how TCP timestamps are incremented (or supported
at all) that may be different from the mask site. To combat this, we can filter
mask sites by those that have identical TCP/IP stacks to ours, as we use a
common Linux implementation. We also note that this attack only applies when we
use the mask site as an application, and that Dark Decoys can support other
applications (e.g. obfsproxy, WebRTC, etc) that do not have this issue.



\paragraph{Website Fingerprinting}

Website Fingerprinting~\cite{wang2014effective,hayes2016k,sirinam2018deep} (WF) uses the patterns of encrypted traffic to identify which website a client is connected to. WF uses a classifier to label the traffic as belonging to one of several known websites, or (in some variants), an unknown or background class. Though WF is commonly studied in the context of anonymous web browsing, a censor could also use WF to detect refraction networking by distinguishing known traffic patterns of legitimate uses of a decoy site from the traffic generated by refraction networking (unknown class). Alternatively, the censor could monitor all traffic for patterns consistent with a set of blocked websites.

Dark Decoy applications that mimic specific websites (e.g., mask sites) are likewise susceptible to WF. To date, however, censors have not been observed using WF and similar techniques, possibly due to the significant uncertainty resulting from even the best algorithms: even a small false
positive rate means blocking mostly legitimate connections (due to the base rate
of normal traffic), and false negatives could allow clients to retry until they
gain access.

More importantly, Dark Decoy applications offer great flexibility in deploying traffic analysis defenses; for example, traffic shaping strategies such as implemented in Slitheen~\cite{slitheen16} could be easily employed in Dark Decoys. Furthermore,
Dark Decoy applications are not limited to mimicking websites, and can support
any (or even a combination of) protocols. Finally, if encrypted SNI can be used (\cref{esni}), the censor would not be able to build up a traffic profile of a legitimate site since its identity would be encrypted.

\paragraph{ICMP}
Censors can use ping or traceroute utilities (via ICMP) to probe potential dark
decoys. Because there is (usually) no host at the dark decoy address, these
probes will timeout and produce no response. They might also produce
``Destination Unreachable'' responses from routers depending on how they are
configured. We performed a scan of 10~million IPv6 addresses in a routable /32
prefix to see if it is common to respond with such tell-tale ICMP messages for
unused messages. We found only 0.016\% of addresses responded with any ICMP
messages (a combination of ``Time Exceeded'' and ``Destination Unreachable'').

Many legitimate hosts and routers do not respond to or forward ICMP packets, and
it is common for firewalls to block traceroutes from penetrating inside
networks. Thus, simply ignoring ICMP messages (or low TTL packets that might be
used by traceroute) may be a viable strategy. % We should evaluate this claim...
Alternatively, we could spoof responses to convince an adversary that a dark
decoy is part of a particular network. However, this strategy requires careful
consideration of what network makes sense for a mask site to be in. Also, the
censor may try to probe for addresses around the dark decoy (but still likely to
be in the same network), which must also be responded to.



%-Fingerprinting Masked site vs Dark decoy application
%-ICMP

\FigIpBits

\paragraph{Address entropy}
Addresses in IPv6 are commonly shortened, as many of the 128-bits in the address are set to 0.
For instance, google.com has the address
\texttt{2607:f8b0:400f:0806:0000:0000:0000:2004} (which can be shortened to
\texttt{2607:f8b0:400f:806::2004}). Only 24 bits are set to 1 in this address,
giving censors a possible feature to filter on: addresses that have too much
entropy (or even simply bits set) could be suspicious as dark decoys. To demonstrate and quantify
this problem, we measured 30 minutes of IPv6 traffic to our ISP's /32 network prefix.
Figure~\ref{fig:ipbits} shows a histogram of bits set in the addresses we observed, which are
notably skewed to less than expected if addresses were randomly generated. However, there
are still a significant number of networks that appear to have random-looking addresses,
making it difficult for censors to block these addresses outright. For a specific deployment,
operators should be careful to observe the distribution of addresses in the subnets they use,
and possibly limit to randomizing ``realistic'' bits (e.g. the middle and/or last 32 bits).



\input{related}
% 0.5-0.75 page



\section{Future Work}
% 0.5 page

\scheme provides a much larger degree of engineering flexibility than previous
Refraction Networking schemes. Due to its modular design, different registration
protocols and applications can be used. One obvious direction is to further
study such alternatives. For instance, while we use a TapDance-like
registration, we could potentially cut down on the overhead of one-time
registration by using port-knocking or using a Telex-style~\cite{telex11} tag (in the Client
Hello rather than Application Data).

\paragraph{Client-side applications}
On the application side, \scheme provides an interesting opportunity to explore
\emph{client mimicking} dark decoys. Rather than pretend to be a server (e.g.
mask site), our application could connect back to a client after registration
from the dark decoy address. Protocols like WebRTC mentioned in
Section~\ref{sec:webrtc} or other peer-to-peer protocols such as BitTorrent,
Skype, or Bitcoin.


\paragraph{Traffic Analysis}
\scheme could also support applications that tradeoff performance for
observability. While Slitheen offers ideal mimicry of decoys, it comes at a high
cost of overhead. \scheme mask site applications could implement Slitheen
in order to perfectly mimic the mask site's latency, packet timings, and payload
sizes. In addition, careful choice of mask sites may allow for higher
performance, as sites with more replaceable content can carry more covert data.


\paragraph{Long-term Deployment}
Ultimately, the goal for Refraction Networking protocols is to be useful in
circumventing censorship. While it has taken many years for research
protocols to mature, we are excited to see schemes like TapDance deployed in
practice~\cite{frolov2017isp}. We believe \scheme can be even easier to deploy
at scale, and hope to leverage the existing success of TapDance to place \scheme
stations in real-world ISPs.

\section{Conclusion}
%.25 page

\TODO{Write (0.25 page}

%%-------------------------------------------------------------------------------
%\section*{Availability}
%%-------------------------------------------------------------------------------
%
%USENIX program committees give extra points to submissions that are
%backed by artifacts that are publicly available. If you made your code
%or data available, it's worth mentioning this fact in a dedicated
%section.

%-------------------------------------------------------------------------------

\bibliographystyle{plain}
\small
\bibliography{biblio}

\end{document}

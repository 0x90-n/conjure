\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}

% For submission make this a noop
\newcommand{\note}[2]{\textit{[#1: #2]}}
\newcommand{\nikita}[1]{\note{nikita}{#1}}

% to be able to draw some self-contained figs
\usepackage{tikz}
%\usepackage{parskip}
\usepackage{amsmath}
\usepackage{wasysym}
%\setlength{\parskip}{1pt} % 1ex plus 0.5ex minus 0.2ex}
\setlength\parskip{1pt}
\usepackage{graphicx} % http://ctan.org/pkg/graphicx
\usepackage{booktabs} % http://ctan.org/pkg/booktabs
\usepackage{xparse}   % http://ctan.org/pkg/xparse%don't print date
\NewDocumentCommand{\rot}{O{45} O{1em} m}{\makebox[#2][l]{\rotatebox{#1}{#3}}}%
\include{figures}
\usepackage{subcaption}
\usepackage{cleveref}
\usepackage{microtype}

% Slight JAH fix to stop URLs from breaking after ``http:''
\def\UrlBreaks{\do-\do\.\do\@\do\\\do\!\do\_\do\|\do\;\do\>\do\]%
 \do\)\do\,\do\?\do\'\do+\do\=\do\#}
\def\UrlBigBreaks{\do\:\do\/}%
\urlstyle{rm}

\begin{document}

\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Dark Decoys:
  Conjuring Proxies from Unused Address Space}

%for single author (just remove % characters)
%\author{
%{\rm Your N.\ Here}\\
%Your Institution
%\and
%{\rm Second Name}\\
%Second Institution
%% copy the following lines to add more authors
%% \and
%% {\rm Name}\\
%%Name Institution
%} % end author

\maketitle

%-------------------------------------------------------------------------------
\begin{abstract}
%-------------------------------------------------------------------------------
Refraction Networking (formerly ``Decoy Routing'') has emrged as a useful tool in circumventing
        Internet censorship. By placing proxies in cooperating Internet Service
        Providers (ISPs) and using connections to existing reachable
        ``decoy'' sites for transport, censors cannot easily block access to
        such proxies without also blocking legitimate sites.

However, existing deployed Refraction Networking schemes such as TapDance suffer
from several problems, including a limited number of decoy sites in realistic
deployments, and an unfavorable tradeoff between performance and observability
by the censor. These problems limit where such proxies can be deloyed, hamper
their effectiveness, and may ultimately make them possible for censors to block.

In this paper, we present Dark Decoys, a deployable Refraction Networking scheme that
overcomes the limits on decoys and performance. Dark Decoys leverages the (primarily) unused address
space that is reachable through the deploying ISP. Rather than rely on existing
sites as reachable decoy sites that must be involved in each proxy connection,
Dark Decoys create seemingly legitimate hosts at new IP addresses. These
invented hosts are indistinguishable from normal hosts to the censor, but can
be used by clients as one-time proxies.

We implement our scheme ... and it's just the bee's knees. TODO

\end{abstract}


%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------
% 1.5-2 pages



%Censorship circumvention still important
%-More countries blocking
%-Existing countries blocking more
Internet censorship continues to hamper social progress throughout the world.
Over half of the global Internet population
now live in countries that block political, social, or religious content
online~\cite{fotn2018} as governments continue to expand their censorship
policies and programs.


%Existing circumvention strategies on shaky ground
%-domain fronting going away
%-active probing of existing proxies
%-Cenosrs fingerprinting known protocols
Meanwhile, strategies to circumvent censorship using proxies have suffered many
recent setbacks. Many previously popular proxies are no longer functional due to
censors evolving new ways to block them~\cite{ensafi-tor,great-cannon},
or because they rely on temperamental
infrastructure. For example, domain fronting was a popular circumvention
strategy used by meek (in Tor), as well as the Signal secure messaging app to
get around censorship in countries it was
blocked~\cite{domain-fronting,signal,signal-domain-fronting}.
But in May~2018, Google and Amazon made both technical and policy changes to
their cloud infrastructures that removed support for domain
fronting~\cite{aws-front}. While meek
continues to use other cloud providers that (for now) continue to allow domain
fronting, Signal abandoned the strategy altogether~\cite{signal-back-on-front}.
%Combined with censors' constant improvements in discovery and blocking
%techniques~\cite{ensafi-tor,great-cannon}, ...


%Importance of Refraction Networking
%-what it is, how it solves many of the above problems
%-acknowledge challenge of ISP deployment, cite TapDance deployment as only refraction technology that has overcome this challenge so far
One emerging technique is Refraction Networking (also known as ``Decoy
Routing''), which places proxies at cooperating Internet Service Providers
(ISPs) outside censoring countries~\cite{refraction-site}. Clients access the
proxies by connecting to unblocked ``decoy'' sites such that the packets pass by
the ISP proxy, which intercepts and injects responses as the decoy site.
Censors cannot easily block access without also blocking
legitimate connections to the decoy sites, which may be costly for the censor.
However, deploying such schemes in practice is more difficult than existing proxies:
convincing ISPs to deploy proxies in their production network is a significant
operational hurdle. To date, only one of six Refraction
Networking schemes has been deployed in practice by a large ISP:
TapDance~\cite{tadance}, a
Refraction Networking protocol that removes the need for inline
flow-blocking~\cite{frolov2017isp}.


%Challenges remain in Tapdance:
%-Censor can fingerprint decoy sites
%-Decoys themselves are limited (e.g. a few dozen in many cases)
%-Can't have long-lived connections (performance and observability issue)
%-Other performance limits (upload limit, TCP window size)
But in order to be deployed, TapDance makes an aggressive tradeoff
between observability by censors for the sake of ease of deployment.
For instance, TapDance's passive ``on the side'' architecture
does not resist active probing attacks, where the censor can send packets that
confirm whether or not a suspected connection is indeed a TapDance connection.
The use of real-world decoy sites also presents practical problems: If
decoys are limited or not particularly important, it may be easy for a
censor to block them altogether without much collateral damage. In addition,
TapDance has several performance limitations due to its interaction with
real decoys. For example, TapDance clients' individual connection duration and upload
capacities are limited due to the interaction with the decoy's TCP and TLS stack
behavior. This forces TapDance to multiplex long-lived proxy connections over
several repeated shorter-duration decoy connections, which increases overhead and may
produce a connection pattern that is visible to censors.


\FigHighLevel

\medskip

%Dark decoys solve these issues
%-Create new decoys from ``dark'' (unused) address space
%-Clients register (via TapDance-like or other robust protocol (email, blockchain, whatever))
%-Connect to custom IP address, talk whatever protocol client/station agrees on
In this paper, we present Dark Decoys, a new Refraction Networking protocol that
solves these issues, while maintaining the easy-to-deploy model of TapDance
(i.e. a passive network tap). In our scheme, clients register new fictitious
decoys in the ``dark'' or unused address space of the deploying ISP. Once
registered, clients can connect to these dark decoy IP addresses as if they were
real hosts. The ISP station acts as the other end of these connections, and responds as
if it were a legitimate site or service. To the censor, these dark decoys appear
as legitimate sites or services, and even active probes won't reveal
information that would allow the censor to block them.


%One-time use address advantages:
%-Censor cannot actively probe ahead of time (especially in IPv6), making it hard to fingerprint
%-Decoys are now virtually unlimited (or limited only by address space)
%-Connection can live as long as we want
%-No pesky TCP/TapDance-y limits
Dark decoys are cheap to create, allowing for discardable \textbf{one-time use}
addresses to be used by clients. This greatly increases the cost for censors to
block, as they must detect and block in real time. Meanwhile, even a censor that
can detect 90\% of dark decoys does not significantly increase the cost to the
circumvention system, giving dark decoys an advantage in the censor/circumventor
cat-and-mouse game.
We support both IPv4 and IPv6 dark decoys, though we note they are especially
powerful in IPv6 where censors cannot exhaustively scan ahead of time to
identify addresses that change behavior.
Because we fully control the server side, dark decoy connections can live as
long as needed, without the upload or timing limits faced by TapDance.


%TODO:
%Requirements/Challenges
%-Censor can't be able to distinguish between dark decoy and legitimate hosts
%    (otherwise they block all dark decoys)
%    -Includes active probing: censor shouldn't be able to register existing IP
%-Disruption avoidence: Want to pickup even for used addresses
%    -Otherwise, censor probes to find truly unused address space and blocks
%    -But can't disrupt legitimate services
%    -Can overcome by limiting pickup to the registering client (but spoofing challenges...)
%    -Note: also likely solved by the client-sends-SNI in the Mask site application...



% We implement it, it works...
We implement our dark decoy protocol under the same model as TapDance using
only a passive tap at an ISP. Furthermore, our protocol also works with
asymmetric routing (i.e. when the tap can only see packets from but not to the
client). We test our deployment on a 10~Gbps real-world ISP testbed similar to the
TapDance deployment~\cite{frolov2017isp}, and evaluate the performance and
observability compared to TapDance.



\input{background.tex}


\section{Threat Model}
% 0.25 page


Our deployment model is identical to that of TapDance: we only require a passive
tap at the deploying ISP, and the ability to inject (spoofed) traffic from dark
decoy sites. However, we assume a stronger threat model for the adversary than
TapDance, as our design resists active attacks.


We assume the censor can block arbitrary IP addresses and networks, but faces a
cost in doing so if it blocks potentially useful resources. In particular, we
assume it is difficult for the censor to have complete knowledge of legitimate
addresses used, and so instead resorts to a blacklist approach to blocking
proxies and objectionable content.
Whitelists are expensive for censors to maintain and can stifle
innovation, and are rarely employed by censors.


We assume that the censor can know what network the dark decoy station(s) are
deployed in and the prefixes dark decoys are selected from, but that blocking those
networks outright brings a collateral
damage the censor is unwilling to suffer. Instead, the censor aims to identify
the addresses that are dark decoys, and block only those.

We assume the censor can use the client to register and access its own dark
decoys, but that these will not reveal the dark decoys of other users. The
censor can also actively probe addresses that it sees users accessing, but can
not enumerate the entire dark decoy prefix (e.g. a /32 IPv6 prefix contains
$2^{96} addresses$).

Finally, we assume the censor can replay or preplay any connections that it
suspects involve dark decoys (or their registration) in an attempt to confirm.
However, the censor wishes to avoid disrupting any connections before it
knows for certain they are dark decoy ones, lest they disrupt legitimate
connections. This means that injecting false data or corrupting TLS sessions is
outside the scope of the censor, but that the censor can send non-disruptive
probes (such as stale TCP acknowledgements or other packets that would normally
be ignored). We emphasize that TapDance is observable by censors that can send
TCP packets in suspected connections, but that our protocol is robust against
this class of censor.

%-Censor can block arbitrary addresses (or networks), but faces a cost in doing so (collateral damage)
%-Censor can know what network deploys the dark decoy station
%-Censor knows the dark decoy prefixes distributed in the client, but they contain legitimate hosts
%-Censor can use the client
%-Censor can active probe limited sets, but cannot enumerate the entire prefix (i.e. IPv6 /32)
%-Censor can active probe or (p)replay connections it suspects


\section{Architecture}
% 3 pages

Dark Decoys involve three main steps. First, clients \textbf{register} with the
ISP station,
and agree on the dark decoy IP address that will be used. Next, the client
connects to the agreed upon address, which is terminated by an
\textbf{application} running on the station. Finally, the client \textbf{proves}
to the application that it was the same entity that registered (and not a censor
attempting to probe), and is able to use the application as a proxy.

Similar to previous schemes, our design does not require expensive in-line
flow blocking, and can be accomplished with only a passive tap at the ISP.
Our architecture is also modular, in that the registration and application steps operate
independently, allowing a wide range of flexibility to evade censors. We
describe each of these components.

\subsection{Registration}

Clients can register intent to use the proxy in several covert ways. For
instance, they could use email or other existing intermitently available proxies
to register. In this section, we use a form of Refraction Networking similar to
TapDance to register directly with the station.

Registration is unidirectional (client to server) and does not require any
acknowledgement of receipt. To ensure receipt, clients can attempt to register
multiple times (possibly via multiple methods) with the same information, and expect
that one gets through.

\medskip

To register, clients connect to a \textbf{decoy} site that supports TLS. They
complete the handshake, and send a normal HTTPS request. In TLS, requests (and
responses) are encrypted and sent in an \texttt{Application Data} record. During
registration, the client alters the ciphertext of the \texttt{Application Data} record to
convey a short \textbf{tag} to the ISP station, on path between the client and
decoy site.

The tag contains a public key (encoded to be indistinguishable from random using
Elligator~\cite{elligator}), and a message encrypted under the shared secret
derived from a key exchange with the station's long-term public key hard-coded
in the client software. The station uses its private key to compute the same
shared secret from the (decoded) public key, and decrypts the message in the
tag. The censor, without knowledge of either the station or client's private
key, cannot derive the shared secret, preventing it from being able to decrypt
the message, or learn of its existence.


Inside the message, the client communicates a random \textbf{seed}, and other
configuration-specific information, such as flags to signify version, feature
support, and which set of dark decoy network prefixes the client knows of. The
client and server use a hash of the provided seed to determine which specific
dark decoy IP address to register. It may seem intuitive to instead have the client
send the specific IP address to register, but allowing the client arbitrary
choice also allows the censor to register suspected dark decoys and block them if
they pick up. By using a hash, the censor would have to pre-image the hash to
obtain a seed it could use to register for a desired IP address. \nikita{Are we claiming that this kind of enumeration is hard to do in IPv4?} It also gives a
secret (the seed) that only the client and station know, even after the client
connects to the dark decoy address.

Once the dark decoy IP address has been selected, the station watches for
packets destined to that address, and forwards them onto the dark decoy
\textbf{application}. The station can also optionally ignore packets not from
the source IP address of the registering client, so that to a probing censor,
the dark decoy appears to be firewalled off from all but the client.

%-IPv6 vs IPv4 dark decoys subsection?

\subsection{Address utilization}
% TODO:Can be better: story for v4, these are some problems, here's what it
% looks like in v6

% Note on IPv6 space? /32 of IPv6 is 96-bits to select...
Dark decoy IP addresses are selected from unused but still routed address
space that passes by the ISP. Traffic to unrouted addresses would produce ICMP
responses that a censor could observe, and are also easily blocked with knowledge
of a routing table. Because we support the use of IPv6 addresses, censors will
also be unable to scan ahead of time to determine if the host has been there
previously, or what was there before. While they can probe suspected dark decoy
addresses after clients connect to them, at that point the address has already been
registered, preventing the censor from identifying differences in behavior
before and after registration.

While address utilization in IPv4 is quite high (all blocks have been allocated
at the RIR level), the fraction of addresses that respond to TCP connections on
a given port is quite low: even popular ports like 443 (use by TLS) have less
than 2\% of IPv4 hosts respond to connection requests. This leaves a large
number of hosts available to use as dark decoys. However, if a client registers
a dark decoy address that is already happens to be used by an existing host,
there will be multiple responses when the client tries to connect, and the
connection will fail. However, this failure is still limited to the registering
client, as the application only responds to the IP of the client that
registered. In IPv6, the odds of picking a legitimate host are negligible: with
a /32 prefix of IPv6, there are $2^{96}$ addresses to choose from.
\nikita{/32 is pretty big, e.g. UIUC only has a /48}


\subsection{Applications}


Once the client has registered, packets sent to the dark decoy IP address are
passed to the \textbf{application} running on the station. The application has
two main jobs: first, it must look like an innocuous legitimate service to the
censor, and second must allow the client to use it as a proxy.

Any protocol that satisfies these criteria can be used as an application. For
instance, \texttt{obfs4}~\cite{obfs4} is a pluggable transport used by
Tor~\cite{tor} that could be
modified to meet these needs: it requires each endpoint to have knowledge of a
shared secret (which we can derive from the seed shared by the client and
station during registration), and attempts to be a protocol with no discernible
fingerprint. Probing censors that do not have the shared secret receive no
response, while clients that have the secret can communicate with the proxy.

However, even though \texttt{obfs4} is indistinguishable from random, there are
still known attacks that can differentiate it from other
traffic~\cite{wang2015seeing}. While we have yet to see evidence of such attacks
employed in practice by censors, we consider two alternatives built on TLS.


\FigOverview

\subsubsection{Mask Sites}

TLS is a natural protocol for dark decoy applications, because it is ubiquitous on
the Internet (making it difficult for censors to block), while also providing
strong cryptographic protection against passive and active network adversaries.
However, there are several challenges to make it robust against censors that
wish to block a particular service.

This is because TLS sends important server-identifying content in plaintext
during the TLS handshake. This includes the Server Name Indication (SNI) in the
Client Hello message that sends the domain name of the server, and the
X.509 Certificate sent by the server.

To evade censors, we must send a plausible SNI value (sending no SNI is
uncommon and easily blocked---only 1\% of TLS connections\nikita{qualify this as being true in a particular sample} do not carry the
SNI extension~\cite{tls-fingerprint}), and we must have the server respond with
a plausible (and corresponding) certificate. Even if we manage to avoid sending
either in the clear, censors could actively probe the server in a
way that would normally elicit a certificate.


We therefore attempt to mimic an existing \textbf{mask site}, by relaying
traffic between the client and a selected mask website. To a censor, this site
will be indistinguishable from the legitimate mask site, making it difficult for
them to block without potentially blocking the actual site. TLS connections to the
application will terminate exactly as connections to the mask site would, with the
application acting as a transparent proxy between the client and mask site.
However, this leaves the application unable to introspect on the contents of the
TLS connection to the mask site, as it does not have the client-site shared
secrets, and it cannot overtly man-in-the-middle the connection before knowing
it is communicating with the legitimate client (and not the censor).


To accomplish this, the client changes the shared secret it derives with the
mask site to something that the application can also derive. The client's first
\texttt{Application Data} packet is thus encrypted under a different secret than
the client/mask site secret. Specifically, the client uses the \textbf{seed}
sent during registration to derive the pre-master secret for the connection.
This is hashed along with the client and server randoms of the current (mask
site) TLS connection to obtain the master secret that determines
encryption/decryption/authentication keys.

The application can determine if the client did this by trial decryption with
the master secret derived from the known \textbf{seed}. If it succeeds, the
client has proved knowledge of the \textbf{seed}, and the application can
respond as a proxy. If not, the application simply continues to forward data
between the client and the mask site. As the censor does not have knowledge of
the \textbf{seed} used in registration, it cannot coerce the application to
appear as anything besides the mask site.


\paragraph{Mask Site Selection}

Selecting which sites to masquerade as must be done carefully to avoid censors
being able to detect obvious choices. For example, if a small university network
has a dark decoy in their network that appears to be \texttt{apple.com}, it
would be easy for a censor to block as a likely non-legitimate host. Likewise,
if a dark decoy at an IP address pretends to be a domain (\texttt{example.com}) that
globally resolves to a single different IP address, the censor could also
identify and block the dark decoy.

\smallskip
\noindent
\emph{Nearby sites} - One strategy for selecting mask sites to mimic is to pick websites that are
legitimately hosted in or near the network of the dark decoy addresses. This
effectively creates copies of legitimate sites, with the censor unable to
determine which copies are real and which are the dark decoys. However, as
mentioned, other signals such as DNS may reveal the true mask site.

\smallskip
\noindent
\emph{Alexa sites} -
An alternative strategy is to use popular sites, such as those from the Alexa
top million~\cite{alexa} list. As mentioned previously, it may be wise to avoid
sites that are obviously not hosted in the dark decoy address range, such as
large companies that run their own datacenters and own their own ASN.
The list could also be filtered to domains that resolve to different IP
addresses from different vantage points, making it harder for a censor to know
if a dark decoy corresponds to a domain's IP.

\smallskip
\noindent
\emph{Passive observation} -
The ISP tap could also collect sites by passively observing DNS requests, TLS
SNI, or certificates that pass by. This would allow for building a realistic set
of sites that are plausibly in the vicinity of the dark decoy addresses
that pass by the tap. It also has the added bonus of being able to discover
IPv6 addresses that could be used as decoys (for registration), where active
scanning would be infeasible.

In practice, clients can often try multiple dark decoys/mask sites over
several attempts, as blocking the client outright may negatively impact other
unrelated users behind the same network (e.g. in the case of NAT). Thus, even a
censor that can block most (but not all) mask site only delays access, and
doesn't prevent it outright.

\subsubsection{Encrypted SNI}
\label{esni}

TLS~1.3~\cite{tls13} offers several features that may greatly simplify dark
decoy application design. For instance, TLS~1.3 handshakes include encrypted
certificates, potentially obviating the need to impersonate mask sites.
Unfortunately, TLS~1.3 currently still sends the SNI in the (plaintext) Client
Hello, meaning we would still have to choose a realistic domain to fool a
censor.

However, there are proposals to encrypt the SNI in the Client Hello~\cite{esni},
though none have been implemented or deployed as of early 2019. Nonetheless,
if widely adopted, Encrypted SNI (ESNI) would offer a powerful solution for dark
decoy applications by allowing the domain to remain hidden from the censor.
While the censor could still try to actively probe with guesses for the SNI,
servers could respond with generic ``Unknown SNI'' errors. If such responses
were common for incorrect SNI, the censor's efforts to identify dark decoys
would be frustrated.

\subsubsection{WebRTC}

Dark Decoys could also pretend to be clients instead of servers. This may
potentially give censors less to block on, as actively probing clients is common
to return few or no open ports. Nonetheless, a censor may be hesitant to block
client-to-client communication, as it could block peer-to-peer applications as
well as many video conferencing protocols. WebRTC is a
natural choice for a client-to-client protocol in censorship circumvention,
and is used in existing censorship circumvention schemes like
Snowflake~\cite{snowflake}. Dark decoy applications could also use WebRTC as the
application protocol, convincing the censor that two clients are communicating.

\section{Implementation}

We implemented the Dark Decoy protocol and tested it in a 10~Gbps ISP testbed
with real traffic. Similar to TapDance~\cite{tapdance}, we used PF\_RING to
consume the 10~Gbps link, and feed it to a custom \textbf{detector} written in Rust. The
detector processes all packets and watches for new registrations. It also
forwards all packets sent to a (registered) dark decoy's address to the local
\textbf{application} via an \texttt{iptables} DNAT rule that rewrites the destination IP,
allowing the application to accept and respond to connections using the native
operating system's interface. Figure~\ref{fig:implementation} shows the overall
architecture of our implementation, which we describe next.
% Along with the client?

\FigImplementation

\subsection{Detector}

Our detector is a modified fork of the open source TapDance
implementation~\cite{tapdance-source}.
We implemented our detector in approximately 1,800 lines of Rust (compared to
over 5,000 lines for TapDance)\footnote{excluding (from both) about 3,000 lines
of auto-generated protobuf code}.

We used PF\_RING to load balance the 10~Gbps link over 4~CPU cores. PF\_RING
supports balancing across cores based on flow (5-tuple) or source and
destination IPs. However, both of these options present challenges for our Dark
Decoy detector. One issue is that registrations could be processed on a
different core than the packets sent to that specific dark decoy address. For
instance, a client could have its registration handled by Core 1, while its
packets to the dark decoy address end up on Core 3, which doesn't know about the
original registration.

To address this, we used Redis~\cite{redis} to allow each process to announce
(publish) newly registered decoys to the other cores so they can
add them to their local list of registered dark decoy addresses.
However, this introduces two new problems. First, a core might add a
registration \emph{after} it has already received and processed packets destined
for the specified dark decoy. This typically isn't a problem when running on a
single core, as packets are processed sequentially. Second, each core may
timeout each dark decoy at different times, potentially leading to differing
behavior that is visible to a censor. For instance, if we used the
source/destination IPs to load balance, a censor's packets to a dark decoy could
be processed by a different core than the client. If the censor waits for the
known timeout before sending a probe, its core may have timed out that dark
decoy, while the client's core has refreshed the timeout of the dark decoy due
to active use.

To address the first issue, we force the client to delay sending its connection
to the dark decoy until a short time after registration. In practice, we force
the client to wait until the registration decoy responds before starting a
connection with the registered dark decoy.

To address the second issue, we implemented a new load-balancing algorithm in
PF\_RING to select the core based solely on the destination IP address of the
packet. This still means we must use Redis to tell all of the cores of new
registrations, but that only one core will be responsible for processing all of
the packets sent to a given dark decoy, regardless of who or when it is sent.


\subsection{Application}

We implemented our application in about 500~lines of Golang. Though we note
other protocols (e.g. obfsproxy or WebRTC) could be used as the application, we
implemented a mask site mimicking application, that pretends to be a mask site
when actively probed by the censor.

The application accepts connections to dark decoy addresses forwarded by the
detector and rewritten to the local address using \texttt{iptables}.
The application also receives out-of-band information about registrations from the
detector via a ZMQ~\cite{zmq} connection, which informs the application of the
registering client's IP address, the secret seed, and other configuration
information passed by the client.

Once the application accepts a connection, it initially acts as a transparent
proxy to the mask site specified by the client during registration. The
application parses the handshake, forwarding packets back and forth between
client and mask site without modification, and extracting the server and client
randoms. The application attempts to decrypt the first application data record
from the client using a key derived from the secret seed, and client and server
randoms. We use the uTLS library~\cite{utls} on both the application and client
to allow us to change the TLS secrets being used after the handshake.

If the decryption is successful, the application switches to forwarding
(decrypted) data back and forth with a client-specified endpoint, such as a
SOCKS proxy, which can multiplex multiple client connections over the single
connection to the dark decoy.

\subsection{Client}

Our client is also written in Golang, and uses a TapDance-like protocol for
registration. We note that this protocol should be harder for censors to observe
because it consists of only a single (complete) request, and the station does
not have to spoof packets as the decoy used during registration, only passively
observe them.

After registering, the client connects to the derived dark decoy address, and
switches secrets after the handshake. At this point, a local application (e.g.
SOCKS client) can connect to the client, and it will transparently be connected to
the remote end via the encrypted dark decoy connection.

\if0
In order to scale up to 10Gbps and beyond,
one has to utilize multiple cores and employ load balancing.
We use PF\_RING built-in load balancer \emph{zbalance} to efficiently
distribute load between 4 cores.
Our timeout is based on last IP address usage time, which prevents us from
balancing load based on source IP address,
as censor would be able to observe
same destination IP address picking or not picking up
depending on source IP address.
To avoid such unusual behavior we balance on destination IP.
Since PF\_RING does not feature load balancing based only on destination
IP address, we made a custom implementation of this zbalance policy.

TODO: say it's tested on 10 Gbps

Implementation of the protocol includes 3 components:
dark decoy detector, proxy application, and client.
Dark decoy detector will parse the traffic, searching for registrations in
tagged messages. After detector observes a registration, and negotiates with client
a dark decoy IP,
all packets, that are sent to that dark decoy IP,
will be forwarded into a proxy application.

\subsection{Registration phase}

Each Dark Decoy connection has 2 phases: registration, and usage of a dark decoy.
Registration starts with a handshake that is similar to a TapDance handshake,
but initial HTTP request is complete.
This allows a reachable site to provide a genuine response
to a HTTP GET request of its index page.
Since station does not need to produce a response,
which significantly reduces complexity of a detector,
that does not need to decrypt and inject packets into a TLS connection between
client and a reachable site, as opposed to original TapDance.

Client begins registation by establishing TLS connection
to one of the reachable websites,
path to which passes by our tap.
Client uses a Chosen-Ciphertext Steganography technique~\cite{tapdance} to manupulate
plaintext of a first application data HTTP request
to get desired ciphertext,
and exchange keys with the station.
After client writes Elligator-encoded~\cite{elligator} representative into the ciphertext at a static offset of 92 bytes from the end,
that could be decoded using station's private key,
to negotiate a 32 byte Eligator-encoded~\cite{elligator} shared secret between the client and the station.
That shared secret is used as a seed of SHA-256 based key derivation function (HKDF),
allowing station and client to derive an unlimited amount of shared secrets.

Elligator representative on the wire is immidiately followed by a 6 bytes long AES-GCM-encrypted
fixed size payload(FSP), that holds flags and the size of the variable size payload(VSP).
IV and key for encrypted of both FSP and VSP will be derived from HKDF.
Once FSP is decrypted and the size of VSP is known, station can decrypt the VSP as well.
VSP itself is a protobuf, which allows us to easily change the contents of VSP without risk of version mismatch, and currently contains 3 fields: version of configuration(which includes list of decoys), SNI of mask site, and a presumably blocked target host that client would like to get connected to.

Client will sleep a short randomized period of time before attempting to establish connection to dark decoy.
This is done for 2 reasons: to break potentially observable interflow dependency with a dark decoy connection being established right after a first application layer data packet sent to decoy,
and to give station time.
TODO: why does it need time?

\subsection{Application phase}
Client and station will use HKDF to derive 16 random bytes and use them to
agree on a dark decoy IP address, by applying a simple selection algorithm.
Algorithm is as follows: first, flatten a list of pre-shared avaliable IP
addresses in various subnets into a single indexed list, then make a 128-bit
integer out of 16 random bytes and divide it by the length
of the flattened list, and use the remainder of this division as an index
of the list to pick an IP address.

To thwart active probing attacks, this application will then confirm
that connecting client knows a secret, negotiated during the registration.
If connecting client does know that secret, application will set up proxying,
otherwise it may give censor a response, that acts like that this IP address
is not an open proxy.

TODO: describe MakeConnWithCompleteHandshake?

Note that dark decoy detector and proxy application are only loosely coupled with each other,
making it simple to replace one of them.
We plan to take advantage of encrypted SNI, when it gets widely adopted,
and replace our current proxy implementation with one that uses encrypted SNI
and achieve improved unobservability properties, described in section~\ref{esni}.

\subsection{Languages and LOC counts} % TODO: rename/restructure and complete section
Client is written in Golang and follows the same API as standard TapDance does,
which allows us to reuse existing TapDance CLI wrapper and Android application.

-Language choice (Rust, Go, minimal C)
-Open source (client, station and application)
\fi


\section{Evaluation}
% 1 page

Compare to TapDance performance:
-Connection setup time
-Connection/session lifetime
-Throughput (especially upload vs download)
-Security considerations


\section{Discussion}

\subsection{Comparison to Prior Schemes}

Since 2011, there have been several proposed Refraction Networking schemes.
Telex~\cite{telex}, Cirripede~\cite{cirripede} and Decoy
Routing~\cite{curveball} are ``first generation'' protocols with nearly
identical features. These designs require inline flow blocking at the ISP to
allow the station to intercept flows with detected tags and act as the decoy
host for them. However, inline-blocking is difficult for ISPs to deploy, as it
requires special-purpose hardware to be placed inline with production traffic,
introducing risk of failures and outages that may be expensive for the ISP
and potentially violate their contractual obligations (SLAs).

TapDance~\cite{tapdance} solves the issue of inline-blocking by coercing the
decoy into staying silent, and allowing the station to respond instead. However,
as previously described, this trick comes at a cost: the decoy only stays silent
for a short timeout (typically 30-120 seconds), and limits the amount of data
the client can send before it responds. TapDance clients must keep connections
short and repeatedly reconnect to decoys, increasing overhead and potentially
alerting censors with this pattern. Dark Decoys addresses this issue and allows
clients to maintain long-lived connections to the dark decoy.

Rebound~\cite{rebound} and Waterfall~\cite{waterfall} both focus on routing
asymmetries and routing attacks by the censor. Rebound modifies the client's
packets on the way to the decoy, and uses error pages on the decoy site to
reflect data back to the client. Waterfall only observes and modifies the
decoy-to-client traffic, similarly using error pages on the decoy to reflect
communication from the client to the station. These schemes also provide some
resistance to traffic analysis, as they use the real decoy to reflect data to
the user. Thus, the TCP/TLS behavior seen by the censor more closely matches
that of a legitimate decoy connection. However, latency and other packet-timing
characteristics may be observable, and both schemes require some form of inline
flow blocking.

Slitheen~\cite{slitheen} focuses on addressing observability by replacing
data in packets sent by the legitimate decoy. Thus, even the packet timings and
sizes of a Slitheen connection match that of a legitimate decoy connection.
However, Slitheen also requires inline-blocking, and introduces a large overhead
as it has to wait for the subset of data-carrying packets from the decoy that
Slitheen can safely replace. We note that the Slitheen model of mimicry is
compatible with Dark Decoys, as we could use Slitheen as the application
protocol. Despite using a passive tap, our scheme is effectively inline to the
dark decoy (which won't otherwise respond).

Dark Decoys allow a large amount of flexibility compare to previous schemes.
Because we have significant degrees of freedom in choosing the specific
application the dark decoy will mimic or talk, our scheme can combine the best
of existing Refraction Networking protocols to achieve high performance, be easy
to deploy, and
also be resistant to active attacks such as replaying or probing by the censor.
Table~\ref{tab:compare} lists the existing Refraction Networking schemes and
their features, as compared to Dark Decoys.

\TabCompare

\subsection{Attacks and Defenses}
% 1 page

There are many attacks a censor might attempt to either prevent dark decoys from
being registered or used.

\paragraph{Blocking registration}
To make registration more difficult, censors could block TLS connections to all of the
limited decoys available in a deployment. Using TapDance's current deployment,
this would involve blocking over 1500 sites. We note that such an attack would
completely disable all existing Refraction Networking schemes, as none work
without being able to access legitimate decoys past the station. In dark decoys,
this would only block new registrations, and would not impact users that
previously registered. Furthermore, registrations could also occur over email,
or over lower-bandwidth covert channels, such as port (or even IP) knocking past
the station, that would be more difficult for the censor to block.
%Cirripede previously used a registration protocol that sent covert information via initial
%sequence numbers in arbitrary TCP connections, though we note this solution
%generally requires clients to have root access to their device to control the
%initial sequence numbers. Since most mobile users do not have such control, we
%suggest other methods be used instead.

\paragraph{Scanning masked sites}
The censor could also attempt to fingerprint the masked site and compare it to a
suspected dark decoy application. For instance, if a dark decoy IP responds as
pretending to be \texttt{example.com}, the censor could scan or probe real instances
of \texttt{example.com} on different ports and see how it responds. Then, the
censor can probe the dark decoy IP, and see if it responds similarly (e.g. with
the same set of open ports and payloads for certain kinds of probes). To defend
against this, we forward \emph{all} traffic destined to the dark decoy to the
masked site, including ports that are not relevant to the proxy application
(e.g. non 443). This ensures that above the TCP layer, we appear to be the mask
site. However, there may be differences in TCP/IP implementations, for instance,
how IP IDs are incremented, or how TCP timestamps are incremented (or supported
at all) that may be different from the mask site. To combat this, we can filter
mask sites by those that have identical TCP/IP stacks to ours, as we use a
common Linux implementation. We also note that this attack only applies when we
use the mask site as an application, and that Dark Decoys can support other
applications (e.g. obfsproxy, WebRTC, etc) that do not have this issue.



\paragraph{Website Fingerprinting}
Dark Decoy applications that mimic websites (e.g. mask sites) may be vulnerable
to website fingerprinting, where the censor observes that clients accessing
suspected dark decoy IPs are receiving payloads or packet timings that differ
from legitimate connections to the mask site. This attack is difficult for
censors to carry out because it has high uncertainty: even a small false
positive rate means blocking mostly legitimate connections (due to the base rate
of normal traffic), and false negatives could allow clients to retry until they
gain access. More importantly, unlike previous Refraction Networking protocols,
Dark Decoy applications are not limited to mimicking websites, and can support
any (or even a combination of) protocols.



%\paragraph{Probing Dark Decoys}
%-Active probing TLS connection
%    -Block access unless from registering source IP
%        -cite GFW taking over client IPs for active probing of old obfs
%    -Verify knowledge of seed (but how to respond when verification fails?)

\paragraph{ICMP}
Censors can use ping or traceroute utilities (via ICMP) to probe potential dark
decoys. Because there is (usually) no host at the dark decoy address, these
probes will timeout and produce no response. They might also produce
``Destination Unreachable'' responses from routers depending on how they are
configured. We performed a scan of 10~million IPv6 addresses in a routable /32
prefix to see if it is common to respond with such tell-tale ICMP messages for
unused messages. We found only 0.016\% of addresses responded with any ICMP
messages (a combination of ``Time Exceeded'' and ``Destination Unreachable'').

Many legitimate hosts and routers do not respond to or forward ICMP packets, and
it is common for firewalls to block traceroutes from penetrating inside
networks. Thus, simply ignoring ICMP messages (or low TTL packets that might be
used by traceroute) may be a viable strategy. % We should evaluate this claim...
Alternatively, we could spoof responses to convince an adversary that a dark
decoy is part of a particular network. However, this strategy requires careful
consideration of what network makes sense for a mask site to be in. Also, the
censor may try to probe for addresses around the dark decoy (but still likely to
be in the same network), which must also be responded to.



%-Fingerprinting Masked site vs Dark decoy application
%-ICMP




\section{Related Work}
% 0.5-0.75 page

MultiFlow, The Waterfall of Liberty, Slitheen, Rebound, TapDance, Cirripede, Telex, Decoy Routing
True Cost of RAD, Routing around Decoys
ISP-scale TapDance


\section{Future Work}
% 0.5 page

\section{Conclusion}
%.25 page

%%-------------------------------------------------------------------------------
%\section*{Availability}
%%-------------------------------------------------------------------------------
%
%USENIX program committees give extra points to submissions that are
%backed by artifacts that are publicly available. If you made your code
%or data available, it's worth mentioning this fact in a dedicated
%section.

%-------------------------------------------------------------------------------

\bibliographystyle{plain}
\small
\bibliography{biblio}

\end{document}
